{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d7102a-408c-44db-a558-742a46196b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder, VisionDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import CustomVGG\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb3c55c-19e1-4eda-9697-775807c7d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdefda93-5236-47eb-a12d-f77abafa3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fce622-1e39-4d46-945b-b4dc62e4d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b7425-ea98-4b1d-b9ce-7bc8b8a70c50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b535e1f6-5b2d-4935-a172-aca6540102e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset, WeightedRandomSampler\n",
    "from dataset import get_dataset, get_weighted_sampler, get_concat_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_size = 128\n",
    "batch_size = 128\n",
    "n_worker = 8\n",
    "\n",
    "train_dataset, valid_dataset = get_dataset(input_size)\n",
    "concat_dataset = get_concat_dataset()\n",
    "\n",
    "sample_freq = np.bincount(train_dataset.targets + valid_dataset.targets)\n",
    "sample_weight = np.array([1/sample_freq[x] for x in train_dataset.targets] + [1/sample_freq[x] for x in valid_dataset.targets])\n",
    "sample_weight = torch.from_numpy(sample_weight)\n",
    "sampler = WeightedRandomSampler(sample_weight.type('torch.DoubleTensor'), len(sample_weight)//2)\n",
    "\n",
    "#sampler = get_weighted_sampler()\n",
    "\n",
    "train_loader = DataLoader(concat_dataset, batch_size=batch_size, drop_last=True, sampler = sampler, num_workers=n_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878fa425-8b06-45ff-8045-167ad1df8605",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6609bc5a-44d2-4e76-9fa6-f76d5615f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomVGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  (classifier): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomVGG(bias=True)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('save/vgg9_final.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0520f78-0455-4823-a35c-cc4330f1fc76",
   "metadata": {},
   "source": [
    "## Hook for Rank Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19453ed5-2f6c-49dc-932e-1599ceb9918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = [3, 7, 10, 14, 17, 21, 24]\n",
    "rank_result = [torch.tensor(0.), torch.tensor(0.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccb2c69-821e-47d4-a40b-0833d6933d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_hook(self, input, output):\n",
    "\n",
    "    num_images, num_features = output.size(0), output.size(1)\n",
    "    ranks = torch.tensor([torch.matrix_rank(output[i,j,:,:]).item() for i in range(num_images) for j in range(num_features)])\n",
    "    ranks = ranks.view(num_images, -1).float()\n",
    "    ranks = ranks.sum(axis=0)\n",
    "    rank_result[0] = rank_result[0] * rank_result[1] + ranks\n",
    "    rank_result[1] += num_images\n",
    "    rank_result[0] = rank_result[0] / rank_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860fd9f3-c2b6-46a5-b156-03dba88ef519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(limit=5):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            if batch_idx >= limit:\n",
    "                break\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d42c9-a2e2-4fb3-b90b-6021f0aa894d",
   "metadata": {},
   "source": [
    "## Get Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7f862c-0a91-452d-91d0-e5dc9f89a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1:\n",
      "\n",
      "feature 2:\n",
      "\n",
      "feature 3:\n",
      "\n",
      "feature 4:\n",
      "\n",
      "feature 5:\n",
      "\n",
      "feature 6:\n",
      "\n",
      "feature 7:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranks_dict = {}\n",
    "\n",
    "limit = 5\n",
    "model.eval()\n",
    "\n",
    "for i, cov_id in enumerate(feature_maps):\n",
    "    \n",
    "    print(f'feature {i+1}:')\n",
    "    \n",
    "    cov_layer = model.features[cov_id]\n",
    "    handler = cov_layer.register_forward_hook(get_feature_hook)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            if batch_idx >= limit:\n",
    "                break\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "    handler.remove()\n",
    "    \n",
    "    ranks_dict[cov_id] = rank_result[0].numpy()\n",
    "    \n",
    "    if not os.path.isdir('rank_conv/'):\n",
    "        os.mkdir('rank_conv/')\n",
    "    np.save('rank_conv/'+'/rank_conv' + str(i + 1) + '.npy', ranks_dict[cov_id])\n",
    "\n",
    "    rank_result[0] = torch.tensor(0.)\n",
    "    rank_result[1] = torch.tensor(0.)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f792e-4600-44b8-b7c3-563cd67b8d12",
   "metadata": {},
   "source": [
    "## Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0a3a9e0-0d9d-46e0-b73f-444a0df2a754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomVGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  (classifier): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned = CustomVGG(cfg=[[int(64*0.75)], [int(128*0.75)], [int(256*0.75), int(256*0.75)], [int(512*0.75), int(512*0.75)], [int(512*0.75), 512]], bias=True)\n",
    "model_pruned.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "598017bc-c253-44ec-8133-62d01e31ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg_model(model, oristate_dict):\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "    last_select_index = None\n",
    "\n",
    "    cnt=0\n",
    "    prefix = 'rank_conv/rank_conv'\n",
    "    subfix = \".npy\"\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "\n",
    "            cnt+=1\n",
    "\n",
    "            oriweight = oristate_dict[name + '.weight']\n",
    "            oribias = oristate_dict[name + '.bias']\n",
    "            curweight =state_dict[name + '.weight']\n",
    "\n",
    "            orifilter_num = oriweight.size(0)\n",
    "            currentfilter_num = curweight.size(0)\n",
    "\n",
    "            if orifilter_num != currentfilter_num:\n",
    "\n",
    "                cov_id = cnt\n",
    "                print('loading rank from: ' + prefix + str(cov_id) + subfix)\n",
    "                rank = np.load(prefix + str(cov_id) + subfix)\n",
    "                select_index = np.argsort(rank)[orifilter_num-currentfilter_num:]\n",
    "                select_index.sort()\n",
    "\n",
    "                if last_select_index is not None:\n",
    "                    for pruned_filter_idx, ori_filter_idx in enumerate(select_index):\n",
    "                        for pruned_featmap_idx, ori_featmap_idx in enumerate(last_select_index):\n",
    "                            state_dict[name + '.weight'][pruned_filter_idx][pruned_featmap_idx] = \\\n",
    "                                oristate_dict[name + '.weight'][ori_filter_idx][ori_featmap_idx]\n",
    "                        state_dict[name + '.bias'][pruned_filter_idx] = \\\n",
    "                                oristate_dict[name + '.bias'][ori_filter_idx]\n",
    "                else:\n",
    "                    for pruned_filter_idx, ori_filter_idx in enumerate(select_index):\n",
    "                        state_dict[name + '.weight'][pruned_filter_idx] = \\\n",
    "                            oristate_dict[name + '.weight'][ori_filter_idx]\n",
    "                        state_dict[name + '.bias'][pruned_filter_idx] = \\\n",
    "                                oristate_dict[name + '.bias'][ori_filter_idx]\n",
    "\n",
    "                last_select_index = select_index\n",
    "\n",
    "            elif last_select_index is not None:\n",
    "                for filter_idx in range(orifilter_num):\n",
    "                    for pruned_featmap_idx, ori_featmap_idx in enumerate(last_select_index):\n",
    "                        state_dict[name + '.weight'][filter_idx][pruned_featmap_idx] = \\\n",
    "                            oristate_dict[name + '.weight'][filter_idx][ori_featmap_idx]\n",
    "                state_dict[name + '.bias'] = oribias\n",
    "\n",
    "            else:\n",
    "                state_dict[name + '.weight'] = oriweight\n",
    "                state_dict[name + '.bias'] = oribias\n",
    "                last_select_index = None\n",
    "        \n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            \n",
    "            if last_select_index is None:\n",
    "                state_dict[name + '.weight'] = oristate_dict[name + '.weight']\n",
    "                state_dict[name + '.bias'] = oristate_dict[name + '.bias']\n",
    "                state_dict[name + '.running_mean'] = oristate_dict[name + '.running_mean']\n",
    "                state_dict[name + '.running_var'] = oristate_dict[name + '.running_var']\n",
    "                \n",
    "            else:\n",
    "                for pruned_featmap_idx, ori_featmap_idx in enumerate(last_select_index):\n",
    "                    state_dict[name + '.weight'][pruned_featmap_idx] = oristate_dict[name + '.weight'][ori_featmap_idx]\n",
    "                    state_dict[name + '.bias'][pruned_featmap_idx] = oristate_dict[name + '.bias'][ori_featmap_idx]\n",
    "                    state_dict[name + '.running_mean'][pruned_featmap_idx] = oristate_dict[name + '.running_mean'][ori_featmap_idx]\n",
    "                    state_dict[name + '.running_var'][pruned_featmap_idx] = oristate_dict[name + '.running_var'][ori_featmap_idx]            \n",
    "            \n",
    "        elif isinstance(module, nn.Linear):\n",
    "            \n",
    "            state_dict[name + '.weight'] = oristate_dict[name + '.weight']\n",
    "            state_dict[name + '.bias'] = oristate_dict[name + '.bias']\n",
    "\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c324a9a3-5358-412c-bc9f-9855cc6ad283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading rank from: rank_conv/rank_conv1.npy\n",
      "loading rank from: rank_conv/rank_conv2.npy\n",
      "loading rank from: rank_conv/rank_conv3.npy\n",
      "loading rank from: rank_conv/rank_conv4.npy\n",
      "loading rank from: rank_conv/rank_conv5.npy\n",
      "loading rank from: rank_conv/rank_conv6.npy\n",
      "loading rank from: rank_conv/rank_conv7.npy\n"
     ]
    }
   ],
   "source": [
    "load_vgg_model(model_pruned, model.state_dict())\n",
    "torch.save(model_pruned.state_dict(), 'save/pruned_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea1435-4391-431d-93c7-517d7166a9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightweight",
   "language": "python",
   "name": "lightweight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
