{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbff3bc-2b1f-4725-8b0a-a6530acbd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder, VisionDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import CustomVGG\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa9a869-efcc-414d-aafe-f3f5efddafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    \n",
    "    def before_train(self, **kargs):\n",
    "        pass\n",
    "    \n",
    "    def after_train(self):\n",
    "        pass        \n",
    "    \n",
    "    def before_epoch(self):\n",
    "        pass\n",
    "\n",
    "    def after_epoch(self, inputs):\n",
    "        pass\n",
    "\n",
    "    def before_step(self):\n",
    "        pass\n",
    "    \n",
    "    def after_step(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b73371-04dd-43a1-895c-e39d59ca03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggerHook(Hook):\n",
    "\n",
    "    def before_train(self, **kargs):\n",
    "        self.state = kargs['state']\n",
    "        self.max_epochs = kargs['num_epochs']\n",
    "        print('Start Training...\\n')\n",
    "    \n",
    "    def before_epoch(self):\n",
    "        if self.state['mode'] == 'train':\n",
    "            print('Epoch {}/{}'.format(self.state['epoch'], self.max_epochs ))\n",
    "\n",
    "    def after_epoch(self, inputs):\n",
    "        loss, acc, f1 = inputs['loss'], inputs['acc'], inputs['f1'] \n",
    "        print('[{}] Epoch: {} Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(self.state['mode'].title(), self.state['epoch'], loss, acc, f1))\n",
    "        if self.state['mode'] == 'valid':\n",
    "            print()\n",
    "\n",
    "    def after_train(self):\n",
    "        print('Training complete!')\n",
    "        print('Best f1 score {:.4f} at epoch {}'.format(best_score, best_epoch))\n",
    "\n",
    "class LossMeter(Hook):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.needs = ['loss', 'cnt']\n",
    "        self.writes = []\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        self.loss = 0\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def after_step(self, inputs):\n",
    "        loss, cnt = inputs['loss'], inputs['cnt']\n",
    "        self.cnt += cnt\n",
    "        self.loss += loss * cnt\n",
    "\n",
    "    def after_epoch(self, inputs):\n",
    "        inputs['loss'] = self.loss / self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6f5b98-45cf-4730-9e3d-fd61525e4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    \"\"\"\n",
    "    T  8  3  6  2\n",
    "    R  5  9  3  9\n",
    "    U  0  3  1  4\n",
    "    E  0  9  9  5\n",
    "       P  R  E  D\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.conf_mtx = np.zeros((num_classes, num_classes), dtype=int)\n",
    "        \n",
    "    def accumulate(self, y_pred, y_true):\n",
    "        self.conf_mtx += np.bincount(y_true * self.num_classes + y_pred, minlength=self.num_classes**2).reshape((self.num_classes, self.num_classes))\n",
    "        \n",
    "    def accuracy(self):\n",
    "        return np.diag(self.conf_mtx).sum() / self.conf_mtx.sum()\n",
    "    \n",
    "    def f1_score(self):\n",
    "        tp = np.diag(self.conf_mtx)\n",
    "        precision = tp / np.sum(self.conf_mtx, axis=0)\n",
    "        recall = tp / np.sum(self.conf_mtx, axis=1)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        return np.mean(f1_score)\n",
    "\n",
    "    def reset(self):\n",
    "        self.conf_mtx.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7c7f54-022b-4d99-944f-4ac753942fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixMeter(Hook):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        self.needs = ['pred', 'true']\n",
    "        self.writes = []\n",
    "        self.conf_mtx = ConfusionMatrix(num_classes)\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        self.conf_mtx.reset()\n",
    "        \n",
    "    def after_step(self, inputs):\n",
    "        pred, true = inputs['pred'], inputs['true']\n",
    "        self.conf_mtx.accumulate(pred, true)\n",
    "\n",
    "    def after_epoch(self, inputs):\n",
    "        inputs['acc'] = self.conf_mtx.accuracy()\n",
    "        inputs['f1'] = self.conf_mtx.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dfaa5-7a2b-4b82-941c-5cf5e2b969c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateHook(Hook):\n",
    "    \n",
    "    def before_train(self, **kargs):\n",
    "        self.model = kargs['model']\n",
    "        self.dataloader = kargs['valid_dataloader']\n",
    "        self.criterion = kargs['criterion']\n",
    "        self.device = next(iter(self.model.parameters)).device\n",
    "        self.conf_mtx = ConfusionMatrix(len(self.dataloader.classes))\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def after_epoch(self, inputs):\n",
    "        \n",
    "        running_cnt, running_loss = 0, 0\n",
    "        self.conf_mtx.reset()\n",
    "        self.model.eval()\n",
    "\n",
    "        for inputs, labels in self.dataloader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds, true = preds.cpu().numpy(), labels.cpu().numpy()\n",
    "            self.conf_mtx.accumulate(preds, true)\n",
    "\n",
    "            running_cnt += inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / running_cnt\n",
    "        epoch_acc = self.conf_mtx.accuracy()\n",
    "        f1 = self.conf_mtx.f1_score()\n",
    "\n",
    "        print('Acc: {:.4f} F1: {:.4f}'.format(epoch_acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e861af-3c0c-4316-91f0-0a9d928b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, hooks):\n",
    "        self.hooks = hooks\n",
    "        self.state = {}\n",
    "    \n",
    "    def train(self, model, dataloaders, criterion, optimizer, num_epochs, **kargs):\n",
    "        \n",
    "        self.train_setup(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, num_epochs=num_epochs, **kargs)\n",
    "        \n",
    "        for self.state['epoch'] in range(1, num_epochs+1):\n",
    "            for self.state['mode'] in ['train', 'valid']:\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                for hook in self.hooks:\n",
    "                    hook.before_epoch()\n",
    "            \n",
    "                for inputs in tqdm(dataloaders[self.state['mode']]):\n",
    "\n",
    "                    for hook in self.hooks:\n",
    "                        hook.before_step()\n",
    "\n",
    "                    outputs = self.step_train(inputs) if self.state['mode'] == 'train' else self.step_valid(inputs)\n",
    "\n",
    "                    for hook in self.hooks:\n",
    "                        hook.after_step(outputs)\n",
    "\n",
    "                outputs = {}\n",
    "                for hook in self.hooks:\n",
    "                    hook.after_epoch(outputs)\n",
    "                \n",
    "            if self.state['end']:\n",
    "                break\n",
    "                    \n",
    "        self.train_end()\n",
    "        \n",
    "    def train_setup(self, **kargs):\n",
    "        self.model = kargs['model'] \n",
    "        self.state['epoch'] = 1\n",
    "        self.state['train'] = True\n",
    "        self.state['end'] = False\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        for hook in self.hooks:\n",
    "            hook.before_train(state=self.state, **kargs)\n",
    "        \n",
    "    def train_end(self):\n",
    "        pass\n",
    "\n",
    "    def step_train(self, inputs):\n",
    "        \n",
    "        imgs, labels = inputs\n",
    "        imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
    "\n",
    "        outputs = self.model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "        outputs = {'loss':loss.item(), 'cnt':preds.size(0), 'pred':preds.cpu().numpy(), 'true':labels.cpu().numpy()}\n",
    "        return outputs  \n",
    "\n",
    "    def step_valid(self, inputs):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            imgs, labels = inputs\n",
    "            imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
    "\n",
    "            outputs = self.model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            outputs = {'loss':loss.item(), 'cnt':preds.size(0), 'pred':preds.cpu().numpy(), 'true':labels.cpu().numpy()}\n",
    "        return outputs  \n",
    "\n",
    "    def check_hooks(self):\n",
    "        pass\n",
    "\n",
    "    # print('{} Epoch: {} Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(phase, epoch, epoch_loss, epoch_acc, f1))\n",
    "\n",
    "#     if phase == 'valid':\n",
    "#         if f1 > best_score:\n",
    "#             best_score = f1\n",
    "#             best_epoch = epoch\n",
    "#             patience_cnt = 0\n",
    "#             torch.save(model.state_dict(), os.path.join(save_dir, f'{save_name}.pt'))\n",
    "#         else:\n",
    "#             if patience_cnt == patience:\n",
    "#                 print()\n",
    "#                 print('Training complete!')\n",
    "#                 print('Best f1 score {:.4f} at epoch {}'.format(best_score, best_epoch))\n",
    "#                 print()\n",
    "#                 return\n",
    "#             patience_cnt += 1\n",
    "\n",
    "#         lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60471b18-adeb-4e4d-803d-788755539caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset, WeightedRandomSampler\n",
    "from dataset import get_dataset, get_weighted_sampler, get_concat_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_size = 224\n",
    "batch_size = 128\n",
    "n_worker = 8\n",
    "\n",
    "train_dataset, valid_dataset = get_dataset(input_size)\n",
    "concat_dataset = get_concat_dataset()\n",
    "\n",
    "# sample_freq = np.bincount(train_dataset.targets + valid_dataset.targets)\n",
    "# sample_weight = np.array([1/sample_freq[x] for x in train_dataset.targets] + [1/sample_freq[x] for x in valid_dataset.targets])\n",
    "# sample_weight = torch.from_numpy(sample_weight)\n",
    "# sampler = WeightedRandomSampler(sample_weight.type('torch.DoubleTensor'), len(sample_weight)//2)\n",
    "\n",
    "sampler = get_weighted_sampler()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, sampler = sampler, num_workers=n_worker)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=n_worker)\n",
    "\n",
    "dataloaders = { 'train' : train_loader, 'valid' : valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5ea8a1-074b-447c-8a5c-74cd16b37759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from model import CustomVGG\n",
    "import geffnet\n",
    "\n",
    "cfg = [[int(64*0.75)], [int(128*0.75)], [int(256*0.75), int(256*0.75)], [int(512*0.75), int(512*0.75)], [int(512*0.75), 512]]\n",
    "device = 'cuda'\n",
    "\n",
    "# model = CustomVGG(cfg=cfg, bias=True)\n",
    "# model.load_state_dict(torch.load('save/pruned_final.pt'))\n",
    "\n",
    "model = torchvision.models.vgg11_bn(pretrained=True)\n",
    "model.avgpool = torch.nn.AvgPool2d(7)\n",
    "model.classifier = torch.nn.Linear(512, 6)\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae32f18-a6c8-40b1-aba6-ab3f74fbb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30], gamma=0.1) # change trainer step\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', verbose=True, patience=5) # optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=60, eta_min=0.000001)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62f1da6-21ad-4631-9d99-38809cf07950",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(hooks=[LossMeter(), ConfusionMatrixMeter(6), LoggerHook()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999b326b-fc6f-496e-acd1-f2cdfd8f1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:27<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch: 1 Loss: 1.2850 Acc: 0.5847 F1: 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:15<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid] Epoch: 1 Loss: 1.1124 Acc: 0.6049 F1: 0.5654\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29632/4229285405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29632/736725704.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, dataloaders, criterion, optimizer, num_epochs, **kargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd516c4-b5c8-4f0e-bb9d-210a4e1fe7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightweight",
   "language": "python",
   "name": "lightweight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
